{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic end-to-end training of a LightGBM model\n",
    "\n",
    "Features that are illustrated in this kernel:\n",
    "- data reading with memory footprint reduction\n",
    "- categorical feature encoding using one-hot-encoding (OHE)\n",
    "- resampling to address imbalance of different categories in the data\n",
    "- gradient-boosted decision trees using _**LightGBM**_ package\n",
    "- early stopping in _**LightGBM**_ model training to avoid overtraining\n",
    "- hyperparameter optimisation of the model using random search in cross validation\n",
    "- submission preparation\n",
    "This kernel inherited ideas and SW solutions from other public kernels and in such cases I will post direct references to the original product, that that you can get some additional insights from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_test.csv', 'bureau.csv', 'bureau_balance.csv', 'installments_payments.csv.zip', 'credit_card_balance.csv.zip', 'sample_submission.csv', 'credit_card_balance.csv', 'application_train.csv.zip', 'application_test.csv.zip', 'previous_application.csv', 'sample_submission.csv.zip', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'bureau_balance.csv.zip', 'application_train.csv', 'bureau.csv.zip', 'previous_application.csv.zip', 'POS_CASH_balance.csv.zip']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "PATH = \"/home/mlisovyi/.kaggle/competitions/home-credit-default-risk/\"\n",
    "print(os.listdir(PATH))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data reducing memory pattern for variables.\n",
    "The implementation was copied over from [this kernel](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 286.23 MB\n",
      "Memory usage after optimization is: 59.54 MB\n",
      "Decreased by 79.2%\n",
      "Memory usage of dataframe is 45.00 MB\n",
      "Memory usage after optimization is: 9.40 MB\n",
      "Decreased by 79.1%\n"
     ]
    }
   ],
   "source": [
    "application_train = import_data(PATH+'application_train.csv')\n",
    "application_test = import_data(PATH+'application_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical encoding\n",
    "The function was taken from [this kernel](https://www.kaggle.com/sz8416/simple-intro-eda-baseline-model-with-gridsearch). It allows to do OneHotEncoding (OHE) keeping only those columns that are common to train and test samples. OHE is performed using `pd.get_dummies`, which allows to convert categorical features, while keeping numerical untouched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of train increases from 59.54 to 90.33 MB\n",
      "Memory usage of test increases from 9.40 to 14.27 MB\n"
     ]
    }
   ],
   "source": [
    "# use this if you want to convert categorical features to dummies(default)\n",
    "def cat_to_dummy(train, test):\n",
    "    train_d = pd.get_dummies(train, drop_first=True)\n",
    "    test_d = pd.get_dummies(test, drop_first=True)\n",
    "    # make sure that the number of features in train and test should be same\n",
    "    for i in train_d.columns:\n",
    "        if i not in test_d.columns:\n",
    "            if i!='TARGET':\n",
    "                train_d = train_d.drop(i, axis=1)\n",
    "    for j in test_d.columns:\n",
    "        if j not in train_d.columns:\n",
    "            if j!='TARGET':\n",
    "                test_d = test_d.drop(i, axis=1)\n",
    "    print('Memory usage of train increases from {:.2f} to {:.2f} MB'.format(train.memory_usage().sum() / 1024**2, \n",
    "                                                                            train_d.memory_usage().sum() / 1024**2))\n",
    "    print('Memory usage of test increases from {:.2f} to {:.2f} MB'.format(test.memory_usage().sum() / 1024**2, \n",
    "                                                                            test_d.memory_usage().sum() / 1024**2))\n",
    "    return train_d, test_d\n",
    "application_train_ohe, application_test_ohe = cat_to_dummy(application_train, application_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with category imbalance\n",
    "Use a standard library to to random undersampling on the dominating category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=314)\n",
    "X_rus, y_rus = rus.fit_sample(application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1).fillna(-1), \n",
    "                              application_train_ohe['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting with HyperParameter optimisation\n",
    "We will use LightGBM classifier - LightGBM allows to build very sophysticated models with a very short training time.\n",
    "### Split the full sample into train/test (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus, test_size=0.20, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use test subset for early stopping criterion \n",
    "This allows us to avoid overtraining and we do not need to optimise the number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\"early_stopping_rounds\":10, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up HyperParameter search\n",
    "We use random search, which is more flexible and more efficient than a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_data_in_leaf': sp_randint(100, 500), \n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This parameter defines the number of HP points to be tested\n",
    "n_HP_points_to_test = 20\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 1000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=1000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.75978\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid's auc: 0.761322\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758901\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid's auc: 0.760096\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.760138\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid's auc: 0.761772\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759892\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid's auc: 0.761676\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.760505\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid's auc: 0.761163\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.76197\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid's auc: 0.762403\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.760655\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid's auc: 0.760984\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.761397\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid's auc: 0.762764\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.761287\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid's auc: 0.761777\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.762101\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid's auc: 0.762317\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid's auc: 0.726405\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.728487\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid's auc: 0.729053\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.728669\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid's auc: 0.728669\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid's auc: 0.728412\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid's auc: 0.727368\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.749574\n",
      "[200]\tvalid's auc: 0.755843\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid's auc: 0.757932\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.74882\n",
      "[200]\tvalid's auc: 0.755772\n",
      "[300]\tvalid's auc: 0.757903\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid's auc: 0.757993\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.75012\n",
      "[200]\tvalid's auc: 0.75662\n",
      "[300]\tvalid's auc: 0.758822\n",
      "Early stopping, best iteration is:\n",
      "[310]\tvalid's auc: 0.75903\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.749672\n",
      "[200]\tvalid's auc: 0.756167\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid's auc: 0.757648\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.750812\n",
      "[200]\tvalid's auc: 0.757174\n",
      "[300]\tvalid's auc: 0.758922\n",
      "[400]\tvalid's auc: 0.760078\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid's auc: 0.760701\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.747439\n",
      "[200]\tvalid's auc: 0.754163\n",
      "[300]\tvalid's auc: 0.756385\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid's auc: 0.75724\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.747062\n",
      "[200]\tvalid's auc: 0.754212\n",
      "[300]\tvalid's auc: 0.75673\n",
      "[400]\tvalid's auc: 0.757879\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid's auc: 0.75823\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.747637\n",
      "[200]\tvalid's auc: 0.75426\n",
      "[300]\tvalid's auc: 0.757174\n",
      "[400]\tvalid's auc: 0.758317\n",
      "Early stopping, best iteration is:\n",
      "[422]\tvalid's auc: 0.758684\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.747421\n",
      "[200]\tvalid's auc: 0.754646\n",
      "[300]\tvalid's auc: 0.75681\n",
      "[400]\tvalid's auc: 0.758319\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid's auc: 0.75847\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.748529\n",
      "[200]\tvalid's auc: 0.754822\n",
      "[300]\tvalid's auc: 0.757411\n",
      "Early stopping, best iteration is:\n",
      "[348]\tvalid's auc: 0.757863\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.756234\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid's auc: 0.757702\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.753123\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid's auc: 0.753986\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.753421\n",
      "[200]\tvalid's auc: 0.757149\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid's auc: 0.757234\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.752763\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid's auc: 0.755454\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.753734\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid's auc: 0.757036\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758832\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid's auc: 0.759606\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758695\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid's auc: 0.759719\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758537\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid's auc: 0.75893\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759609\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid's auc: 0.759932\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.75873\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid's auc: 0.759819\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757418\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid's auc: 0.759269\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757834\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid's auc: 0.758204\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759234\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid's auc: 0.76088\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757378\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid's auc: 0.760208\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758258\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid's auc: 0.760964\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.756681\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid's auc: 0.759583\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.7554\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's auc: 0.759305\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.755057\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid's auc: 0.759368\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.755322\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid's auc: 0.759267\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.756673\n",
      "[200]\tvalid's auc: 0.761508\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid's auc: 0.761708\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.756748\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid's auc: 0.758541\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.755933\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid's auc: 0.757646\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.756481\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid's auc: 0.758972\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757762\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid's auc: 0.758734\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757534\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid's auc: 0.757782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758413\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid's auc: 0.758905\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid's auc: 0.758427\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759851\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid's auc: 0.760293\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758525\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid's auc: 0.759022\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.761435\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid's auc: 0.761435\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid's auc: 0.756555\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid's auc: 0.757215\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid's auc: 0.757363\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid's auc: 0.754155\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid's auc: 0.756322\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.756661\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid's auc: 0.757979\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.754646\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid's auc: 0.75528\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.75489\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid's auc: 0.755366\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid's auc: 0.755467\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid's auc: 0.755029\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.742041\n",
      "[200]\tvalid's auc: 0.747724\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid's auc: 0.748571\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.741889\n",
      "[200]\tvalid's auc: 0.74756\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid's auc: 0.748305\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.742349\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid's auc: 0.746626\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.742685\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's auc: 0.747118\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.742945\n",
      "[200]\tvalid's auc: 0.748866\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid's auc: 0.750615\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759568\n",
      "[200]\tvalid's auc: 0.762587\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid's auc: 0.76277\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758099\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid's auc: 0.761451\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759401\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid's auc: 0.763162\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759773\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid's auc: 0.761272\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759026\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid's auc: 0.762218\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.729301\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid's auc: 0.729301\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid's auc: 0.728774\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.732417\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid's auc: 0.733097\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.731819\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid's auc: 0.732615\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid's auc: 0.732749\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759016\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid's auc: 0.760283\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.760014\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid's auc: 0.761421\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.759506\n",
      "[200]\tvalid's auc: 0.762109\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid's auc: 0.762129\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.760088\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid's auc: 0.761871\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.76052\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid's auc: 0.761287\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.747452\n",
      "[200]\tvalid's auc: 0.753336\n",
      "[300]\tvalid's auc: 0.755486\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid's auc: 0.756133\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.746448\n",
      "[200]\tvalid's auc: 0.752648\n",
      "[300]\tvalid's auc: 0.755232\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid's auc: 0.756191\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.748706\n",
      "[200]\tvalid's auc: 0.754765\n",
      "[300]\tvalid's auc: 0.756946\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid's auc: 0.757255\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.749485\n",
      "[200]\tvalid's auc: 0.75478\n",
      "[300]\tvalid's auc: 0.75724\n",
      "Early stopping, best iteration is:\n",
      "[383]\tvalid's auc: 0.758265\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.748745\n",
      "[200]\tvalid's auc: 0.755258\n",
      "[300]\tvalid's auc: 0.757175\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid's auc: 0.757242\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758314\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid's auc: 0.759472\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758161\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid's auc: 0.759213\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758914\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid's auc: 0.760373\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758965\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid's auc: 0.76053\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758755\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid's auc: 0.759971\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758654\n",
      "[200]\tvalid's auc: 0.762081\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid's auc: 0.762204\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.75775\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid's auc: 0.760239\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757576\n",
      "[200]\tvalid's auc: 0.761306\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid's auc: 0.762313\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.758604\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid's auc: 0.761124\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.757804\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid's auc: 0.760448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.761138\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid's auc: 0.76234\n",
      "Best score reached: 0.756326990767207 with params: {'subsample': 0.9326466073236168, 'min_data_in_leaf': 301, 'colsample_bytree': 0.9501241488957805, 'reg_lambda': 100, 'reg_alpha': 0, 'num_leaves': 28} \n"
     ]
    }
   ],
   "source": [
    "gs.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the performance of the top-5 parameter choices\n",
    "(the list is inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid+-Std     Train  :   Parameters\n",
      "0.755+-0.004     0.775   :  {'subsample': 0.6362647988131058, 'min_data_in_leaf': 322, 'colsample_bytree': 0.46175306323300236, 'reg_lambda': 20, 'reg_alpha': 0.1, 'num_leaves': 8}\n",
      "0.755+-0.003     0.807   :  {'subsample': 0.9519134298608098, 'min_data_in_leaf': 171, 'colsample_bytree': 0.9731668400523877, 'reg_lambda': 10, 'reg_alpha': 2, 'num_leaves': 22}\n",
      "0.756+-0.004     0.792   :  {'subsample': 0.858216412736859, 'min_data_in_leaf': 250, 'colsample_bytree': 0.5645098230355559, 'reg_lambda': 50, 'reg_alpha': 10, 'num_leaves': 16}\n",
      "0.756+-0.004     0.790   :  {'subsample': 0.9969185790275723, 'min_data_in_leaf': 221, 'colsample_bytree': 0.9891800664272259, 'reg_lambda': 10, 'reg_alpha': 2, 'num_leaves': 11}\n",
      "0.756+-0.003     0.811   :  {'subsample': 0.9326466073236168, 'min_data_in_leaf': 301, 'colsample_bytree': 0.9501241488957805, 'reg_lambda': 100, 'reg_alpha': 0, 'num_leaves': 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlisovyi/anaconda2/envs/Titanic/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid+-Std     Train  :   Parameters\")\n",
    "for i in np.argsort(gs.cv_results_['mean_test_score'])[-5:]:\n",
    "    print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs.cv_results_['params'][i], \n",
    "                                    gs.cv_results_['mean_test_score'][i], \n",
    "                                    gs.cv_results_['mean_train_score'][i],\n",
    "                                    gs.cv_results_['std_test_score'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6c8ac0e5c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp = pd.Series(gs.best_estimator_.feature_importances_, index=application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1).columns)\n",
    "feat_imp.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the final model\n",
    "We do training with the 0.8 subset of the dataset and 0.2 subset for early stopping. We use the tuned parameter values but a smaller learning rate to allow smoother convergence to the minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[100]\tvalid's auc: 0.721485\n",
      "[200]\tvalid's auc: 0.727349\n",
      "[300]\tvalid's auc: 0.732482\n",
      "[400]\tvalid's auc: 0.737071\n",
      "[500]\tvalid's auc: 0.741618\n",
      "[600]\tvalid's auc: 0.745241\n",
      "[700]\tvalid's auc: 0.748159\n",
      "[800]\tvalid's auc: 0.750491\n",
      "[900]\tvalid's auc: 0.752363\n",
      "[1000]\tvalid's auc: 0.753975\n",
      "[1100]\tvalid's auc: 0.755421\n",
      "[1200]\tvalid's auc: 0.756637\n",
      "[1300]\tvalid's auc: 0.757761\n",
      "[1400]\tvalid's auc: 0.758705\n",
      "[1500]\tvalid's auc: 0.759599\n",
      "[1600]\tvalid's auc: 0.760481\n",
      "[1700]\tvalid's auc: 0.761169\n",
      "[1800]\tvalid's auc: 0.761649\n",
      "[1900]\tvalid's auc: 0.762098\n",
      "[2000]\tvalid's auc: 0.762588\n",
      "[2100]\tvalid's auc: 0.762947\n",
      "[2200]\tvalid's auc: 0.763228\n",
      "[2300]\tvalid's auc: 0.76345\n",
      "[2400]\tvalid's auc: 0.763687\n",
      "Early stopping, best iteration is:\n",
      "[2467]\tvalid's auc: 0.763846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.9501241488957805, learning_rate=0.005,\n",
       "        max_depth=-1, metric='None', min_child_samples=20,\n",
       "        min_child_weight=0.001, min_data_in_leaf=301, min_split_gain=0.0,\n",
       "        n_estimators=5000, n_jobs=4, num_leaves=28, objective=None,\n",
       "        random_state=314, reg_alpha=0, reg_lambda=100, silent=True,\n",
       "        subsample=0.9326466073236168, subsample_for_bin=200000,\n",
       "        subsample_freq=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n",
    "#force larger number of max trees and smaller learning rate\n",
    "clf_final.set_params(n_estimators=5000, learning_rate=0.005)\n",
    "clf_final.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the submission test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = gs.best_estimator_.predict_proba(application_test_ohe.drop(['SK_ID_CURR'], axis=1).fillna(-1))\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': application_test_ohe['SK_ID_CURR'],\n",
    "    'TARGET':     [ row[1] for row in probabilities]\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
